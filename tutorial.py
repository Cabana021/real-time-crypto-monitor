'''
==============================================================
Documenta√ß√£o do Projeto: Monitor de Criptomoedas em tempo real
==============================================================

Este projeto monitora pre√ßos de criptomoedas em tempo real, utilizando uma arquitetura de processamento de streams. 
A solu√ß√£o integra Python, Kafka (mensageria), SQLAlchemy (banco de dados) e Streamlit (dashboard), 
com a API CoinGecko como fonte de dados. Toda a infraestrutura √© orquestrada com Docker Compose.

O fluxo de dados √© simples:
- Producer: Coleta os dados da API e os envia para o Kafka.
- Consumer: Recebe os dados do Kafka e os salva permanentemente no banco de dados.
- Dashboard: L√™ os dados do banco e os apresenta em uma interface interativa.

-----------------------------
1. O Producer (api.py)
-----------------------------
O Producer √© o ponto de partida da pipeline. Sua fun√ß√£o √© buscar os dados de pre√ßo e public√°-los no Kafka.

* Coleta de Dados: A cada intervalo configurado (padr√£o de 60s), a fun√ß√£o `fetch_crypto_prices()` 
faz uma requisi√ß√£o HTTP √† API CoinGecko para obter os pre√ßos atuais das criptomoedas definidas 
em `config.py`, incluindo a varia√ß√£o percentual das √∫ltimas 24h.

* Envio para o Kafka: A fun√ß√£o `send_to_kafka()` formata os dados recebidos em mensagens JSON individuais para cada criptomoeda. 
Cada mensagem cont√©m o ID, o pre√ßo em USD, a varia√ß√£o e um timestamp UTC, garantindo um padr√£o de tempo consistente. 
As mensagens s√£o ent√£o publicadas no t√≥pico do Kafka.

* Robustez na Conex√£o: Para evitar falhas durante a inicializa√ß√£o (quando o Kafka pode ainda n√£o estar pronto), a fun√ß√£o 
`create_producer()` implementa uma l√≥gica de retentativa, tentando se conectar ao Kafka v√°rias vezes antes de encerrar o script.

-----------------------------
2. O Consumer (main.py)
-----------------------------
O Consumer escuta o t√≥pico do Kafka, processa as mensagens e as persiste no banco de dados, transformando 
dados transit√≥rios em registros permanentes.

* Consumo de Mensagens: A fun√ß√£o `create_consumer()` se inscreve no t√≥pico do Kafka. 
Com `auto_offset_reset='latest'`, ele processar√° apenas as mensagens que chegarem ap√≥s sua inicializa√ß√£o.

* Processamento e Persist√™ncia: A fun√ß√£o `process_message()` √© o n√∫cleo do Consumer. 
Ao receber uma mensagem, ela cria um objeto `CryptoPrice` e o salva no banco de dados usando SQLAlchemy. 
O timestamp √© salvo exatamente como veio (em UTC).

* Monitoramento e Alertas: Ap√≥s salvar, o Consumer exibe um log no console com o status do pre√ßo (üìà ou üìâ).
Se a varia√ß√£o de pre√ßo for superior a 5%, um alerta especial √© impresso.

* Robustez: Assim como o Producer, o Consumer possui uma l√≥gica de retentativa de conex√£o. 
Al√©m disso, o processo de escrita no banco est√° dentro de um bloco `try-except` que executa 
um `rollback` em caso de falha, mantendo a integridade dos dados.

---------------------------------
3. O Dashboard (dashboard.py)
---------------------------------
A interface visual do projeto, constru√≠da com Streamlit. Ela l√™ os dados diretamente do banco de dados, nunca do Kafka.

* **Interface Interativa**: A sidebar permite que o usu√°rio selecione o intervalo de tempo dos dados a serem exibidos (1 a 24 horas) 
e ative um auto-refresh de 60 segundos.

* Visualiza√ß√£o de Dados:
    * M√©tricas: Exibe o pre√ßo mais recente de cada criptomoeda e sua varia√ß√£o percentual no per√≠odo selecionado.
    * Gr√°fico de Linhas: Um gr√°fico interativo da Plotly mostra a evolu√ß√£o dos pre√ßos ao longo do tempo.
    * Tabela de Dados: Apresenta os 5 registros mais recentes de cada criptomoeda.
* Convers√£o de Fuso Hor√°rio: Para exibir os hor√°rios de forma correta para o usu√°rio, o dashboard converte os timestamps UTC
do banco de dados para o fuso hor√°rio local (ex: 'America/Sao_Paulo') antes de renderizar os gr√°ficos e tabelas.

* Performance: A conex√£o com o banco de dados √© otimizada com `@st.cache_resource`, que a cria uma √∫nica vez e a reutiliza, 
evitando reconex√µes a cada refresh.

------------------------------------------
4. Orquestra√ß√£o com Docker Compose
------------------------------------------
O arquivo `docker-compose.yml` define e conecta todos os servi√ßos da aplica√ß√£o, criando um ambiente isolado e consistente.

* Ordem de Inicializa√ß√£o: Utiliza `depends_on` para garantir uma ordem de inicializa√ß√£o correta: 
`zookeeper` -> `kafka` -> `producer` & `consumer` -> `dashboard`.

* Rede de Cont√™ineres: Os servi√ßos se comunicam atrav√©s da rede interna do Docker. 
O Producer e o Consumer se conectam ao Kafka usando o nome do servi√ßo (`kafka:9092`).

* Acesso Externo: O Dashboard √© exposto na porta `8501`, permitindo que seja acessado pelo navegador em `http://localhost:8501`.

* Desenvolvimento √Ågil: O c√≥digo-fonte √© montado como um volume dentro dos cont√™ineres, o que permite que altera√ß√µes no c√≥digo 
sejam refletidas em tempo real sem a necessidade de reconstruir as imagens.
'''